{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_j_2MyVtyq3O",
    "outputId": "834ccc6c-d763-4344-8237-2a7054c3d0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==3.6.0\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.35.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "Successfully installed datasets-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kfre_c3LxyRQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, pipeline\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "84c5255106c9490b8a2a08a2373bd6df",
      "5a08b05f841944489ff24981e44bb658",
      "339655aa35ff44cfbefbd83c76bf8698",
      "f6c995e8370341aa8bac468c5f8fc278",
      "a531c4e34e504371a0f8933911c456a6",
      "42ed2838407044f38c3a9822aec237de",
      "c0b6bd9485cc49ba84ef2a79aa1c1eea",
      "577d03e1f6c64a4f85db4734599b0d25",
      "8369bede66ee46bab6de23904e9cb042",
      "8089e5084b2641d8b8864a6c6bd62f30",
      "01debf0c0bab4ab58e34bf27b4b599d2",
      "c8682ca2284a4749b1c64bc235eff240",
      "05ef4d97bb7c4d9d8328ca0db0ba2f3f",
      "47ba2f4eea0a42a68020dbb5d372f778",
      "b781063363d1443ab8b1d2b4b88f75e9",
      "cb6d75341fbf41c5af649c8207aa730f",
      "641893f03b1440a9b83437688dccec60",
      "e5ccba7a1c0b46678f3de3654af3f6c2",
      "813dceba47894cdb8c4a84569983e3c1",
      "83f8817bc4a84bc7903c047508814f69",
      "8b73a547d0bd45a0b995c517fb045f2a",
      "3fca2526be1a4b709407e48a815cb548",
      "87c2dc033c644805af8eed8de93ec5d0",
      "41d56a3d08a04f72a1c05727dae70d78",
      "cb1c6edbd24f44f9962b39ca1e615387",
      "d669fa34eb404796bd49c8fec946efbb",
      "33f2909fab0541259dba8abada21ad1b",
      "9fdf9202875f446e8046bf50aefe194f",
      "870f310b2e2f4cc59b1b78559ccb464d",
      "8b445082c36a4409b11caa1e90b1ff41",
      "c5b0015d813b4b59a6c7fc4a17820c7f",
      "bd64cb33bb1d42cb943359562d629790",
      "e58874230eba419abefe64e64fbd362b",
      "a226d42455d84aada259e1b8692c96b3",
      "d91df45ce9714b5d934afdff33356278",
      "a4a5c897545b45778e42ce4bbab691ed",
      "6f9e70fdceae4242be17f30a9a646b64",
      "f2e1574a9c99414f8a6ffcd02cf17ef1",
      "aaaf55caab884452a286ef675ac522a1",
      "1526bc47163f4796a998345cc274c7a3",
      "8d42e32fe78f41d2b43088a3a007969f",
      "687aad6d72e94c4881266ac8abf89d05",
      "e1a4c3b665154eadb944453379f2e803",
      "68563a7b25fa4d92a3f7f2496fb6ff64",
      "cd7299e16f1240b7aac6017dbcecdd7f",
      "88083c47e5dd4028a2c3ed90cb055e6d",
      "41738b9450f242afa44fb9a77c4e25eb",
      "56ac76cde6ce4b418fb1dcc4ccb72928",
      "dd9209eb410840eca7bdc8aa96b2ec45",
      "eb28632f190f4b958ce079e723c01819",
      "a1471773c29b43098bcaf2d30740233e",
      "56c120878f1345ebacf3a81ef4741fd8",
      "c395daeed4be43d59f54931bd83b1e61",
      "38593c65442f471999f6f42f4fc2c8bf",
      "a5fdfbfe8b4e4fb8a1750e2fdd793aa8"
     ]
    },
    "id": "iRc9lHOCxzwi",
    "outputId": "8ca1c80e-6b6e-4730-c9ab-70957f95a440"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c5255106c9490b8a2a08a2373bd6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8682ca2284a4749b1c64bc235eff240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c2dc033c644805af8eed8de93ec5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a226d42455d84aada259e1b8692c96b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7299e16f1240b7aac6017dbcecdd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1️⃣ Model & Tokenizer\n",
    "# -----------------------------\n",
    "MODEL_NAME = \"EleutherAI/gpt-neo-125M\"  # small model for 6GB VRAM\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT models need pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "a11ee8420f82417f9e501424e4368f29",
      "c418000143094a5aae3da4cc44aa80aa",
      "92b7a1534eab448285e14e534d403dcb",
      "be7b390b597b4876a3b1c919d7d30296",
      "d4c8e11101d04cdebcb45c0e73eec4f5",
      "80a25312c9904fa3ab5b4aca3d1759df",
      "38b5b8867367479b94c3798d17697f72",
      "3a60ec1001654482985fb2ddc02f619e",
      "33fca2edeeb7451cae7fb21d5a972f5e",
      "e0592277ef794cb3a95db54fe93c661a",
      "30be012a5f9b4a098cc6f246e8fa10db",
      "843bccf0e78743cd85a75494163d17f5",
      "93f50a4a56434a18b19c7b4f599b941c",
      "7a840cb726774dedbaa3378f6e4735db",
      "094c675aa0e5410db22da05ba25efdfc",
      "6aba44bffe1a40f1928fcfa27c0395cc",
      "6a73f0ed440f46e2ba526d79ab23c1e1",
      "677d5efdcb4846c5b219a0875ea93ceb",
      "3a627886c44d4ceabbd9f1bad2fa4aec",
      "97f1736ac32240448c897afb6b2b7f36",
      "8784ce56f9394f4da2a281e1e43e012c",
      "2039cf11ca9247f9b6735c6188c93ea9",
      "0fb52c6f56764021bf126f5d8b0ed3fc",
      "72ab233443fc4bf5b43e4c9afdcb77c4",
      "c3ef6c426d614251a4a8b76b9c72e500",
      "3e003c5b7a544cc1ac759b77c97f62b0",
      "d47d2d7e6bf64733ac6892960c60df8b",
      "c195110135da46f887f3ff6f0b68d884",
      "486a0bb5244a4e8586001b33df636a6f",
      "6e0f510e36a1486fbf883530f6584e8c",
      "e73efa294b9940cc835930d7e0e83bad",
      "91a8fb9dff50438f879b895d489c8956",
      "da372a1828f549399974c46b9ee19d03"
     ]
    },
    "id": "Pc52bwCMyRL8",
    "outputId": "173457b8-00fe-4628-e878-f056ff4fe589"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11ee8420f82417f9e501424e4368f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843bccf0e78743cd85a75494163d17f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb52c6f56764021bf126f5d8b0ed3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(f\"Model is on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jidosu8cyUuc"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2️⃣ Load Dataset\n",
    "# -----------------------------\n",
    "# Using a small subset of CodeSearchNet Python for testing\n",
    "dataset = load_dataset(\"code_search_net\", \"python\", split=\"train[:1%]\")  # 1% for quick training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVaV449X02fb",
    "outputId": "205f4d9a-d5fa-42ff-8697-ad2e0599756b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 4122\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mToF9cWV1WVl",
    "outputId": "aaa157d2-8256-4716-cc99-1fe17a527af7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': 'proycon/pynlpl',\n",
       " 'func_path_in_repository': 'pynlpl/formats/folia.py',\n",
       " 'func_name': 'AbstractElement.addidsuffix',\n",
       " 'whole_func_string': 'def addidsuffix(self, idsuffix, recursive = True):\\n        \"\"\"Appends a suffix to this element\\'s ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\\n        if self.id: self.id += idsuffix\\n        if recursive:\\n            for e in self:\\n                try:\\n                    e.addidsuffix(idsuffix, recursive)\\n                except Exception:\\n                    pass',\n",
       " 'language': 'python',\n",
       " 'func_code_string': 'def addidsuffix(self, idsuffix, recursive = True):\\n        \"\"\"Appends a suffix to this element\\'s ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\\n        if self.id: self.id += idsuffix\\n        if recursive:\\n            for e in self:\\n                try:\\n                    e.addidsuffix(idsuffix, recursive)\\n                except Exception:\\n                    pass',\n",
       " 'func_code_tokens': ['def',\n",
       "  'addidsuffix',\n",
       "  '(',\n",
       "  'self',\n",
       "  ',',\n",
       "  'idsuffix',\n",
       "  ',',\n",
       "  'recursive',\n",
       "  '=',\n",
       "  'True',\n",
       "  ')',\n",
       "  ':',\n",
       "  'if',\n",
       "  'self',\n",
       "  '.',\n",
       "  'id',\n",
       "  ':',\n",
       "  'self',\n",
       "  '.',\n",
       "  'id',\n",
       "  '+=',\n",
       "  'idsuffix',\n",
       "  'if',\n",
       "  'recursive',\n",
       "  ':',\n",
       "  'for',\n",
       "  'e',\n",
       "  'in',\n",
       "  'self',\n",
       "  ':',\n",
       "  'try',\n",
       "  ':',\n",
       "  'e',\n",
       "  '.',\n",
       "  'addidsuffix',\n",
       "  '(',\n",
       "  'idsuffix',\n",
       "  ',',\n",
       "  'recursive',\n",
       "  ')',\n",
       "  'except',\n",
       "  'Exception',\n",
       "  ':',\n",
       "  'pass'],\n",
       " 'func_documentation_string': \"Appends a suffix to this element's ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\",\n",
       " 'func_documentation_tokens': ['Appends',\n",
       "  'a',\n",
       "  'suffix',\n",
       "  'to',\n",
       "  'this',\n",
       "  'element',\n",
       "  's',\n",
       "  'ID',\n",
       "  'and',\n",
       "  'optionally',\n",
       "  'to',\n",
       "  'all',\n",
       "  'child',\n",
       "  'IDs',\n",
       "  'as',\n",
       "  'well',\n",
       "  '.',\n",
       "  'There',\n",
       "  'is',\n",
       "  'sually',\n",
       "  'no',\n",
       "  'need',\n",
       "  'to',\n",
       "  'call',\n",
       "  'this',\n",
       "  'directly',\n",
       "  'invoked',\n",
       "  'implicitly',\n",
       "  'by',\n",
       "  ':',\n",
       "  'meth',\n",
       "  ':',\n",
       "  'copy'],\n",
       " 'split_name': 'train',\n",
       " 'func_code_url': 'https://github.com/proycon/pynlpl/blob/7707f69a91caaa6cde037f0d0379f1d42500a68b/pynlpl/formats/folia.py#L1263-L1271'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "eYmcFVmkyWSH",
    "outputId": "b887e7c9-5ffa-4e8f-c2d2-fe2e07b422da"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'def addidsuffix(self, idsuffix, recursive = True):\\n        \"\"\"Appends a suffix to this element\\'s ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\\n        if self.id: self.id += idsuffix\\n        if recursive:\\n            for e in self:\\n                try:\\n                    e.addidsuffix(idsuffix, recursive)\\n                except Exception:\\n                    pass'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['whole_func_string'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UMb9Jm0DzYHq"
   },
   "outputs": [],
   "source": [
    "# Build input-output pairs: docstring + function name + language as input, code as target\n",
    "inputs, outputs = [], []\n",
    "for example in dataset:\n",
    "    docstring = example.get('func_documentation_string', '')\n",
    "    func_name = example.get('func_name', '')\n",
    "    language = example.get('language', 'python')\n",
    "    code = example['whole_func_string']\n",
    "\n",
    "    # Input: docstring + function name + language\n",
    "    input_text = f\"# Language: {language}\\n# Function: {func_name}\\n\\\"\\\"\\\"{docstring}\\\"\\\"\\\"\\n{func_name}(\"\n",
    "    output_text = code[len(func_name):]  # rest of function code after the name\n",
    "    inputs.append(input_text)\n",
    "    outputs.append(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NNGPBXcH2mQd"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4️⃣ Tokenize Dataset\n",
    "# -----------------------------\n",
    "import torch\n",
    "\n",
    "MAX_LEN = 512\n",
    "tokenized_texts = []\n",
    "\n",
    "for inp, out in zip(inputs, outputs):\n",
    "    enc = tokenizer(inp + out, truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].copy()  # important!\n",
    "    # mask padding\n",
    "    enc[\"labels\"] = [l if l != tokenizer.pad_token_id else -100 for l in enc[\"labels\"]]\n",
    "    tokenized_texts.append(enc)\n",
    "\n",
    "full_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": [t[\"input_ids\"] for t in tokenized_texts],\n",
    "    \"attention_mask\": [t[\"attention_mask\"] for t in tokenized_texts],\n",
    "    \"labels\": [t[\"labels\"] for t in tokenized_texts],  # <- add labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gBYOCpCP56PC"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5️⃣ Train / Eval Split\n",
    "# -----------------------------\n",
    "split_index = int(0.9 * len(full_dataset))\n",
    "train_dataset = full_dataset.select(range(split_index))\n",
    "eval_dataset = full_dataset.select(range(split_index, len(full_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lrmBcH4563Ho"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # causal LM, not masked LM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0bkfBgI828_v"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4️⃣ LoRA Configuration\n",
    "# -----------------------------\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # low-rank for low VRAM\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # attention layers only\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ns-1bG0n3WOi",
    "outputId": "67958ef8-aea5-4480-c094-697fa933644d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 125,788,416 || trainable%: 0.4689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # only LoRA params are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hoibDBpQ3g8B"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5️⃣ Training Arguments\n",
    "# -----------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True if device==\"cuda\" else False,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LbCZxcc3350N"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6️⃣ Trainer\n",
    "# -----------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "2KidmhPe6ESD",
    "outputId": "68e03ed0-a483-4a36-c0cd-c91832adb393"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1392' max='1392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1392/1392 13:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.325300</td>\n",
       "      <td>1.432426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.237000</td>\n",
       "      <td>1.394757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>1.356186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.212600</td>\n",
       "      <td>1.332668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.205900</td>\n",
       "      <td>1.319527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.267400</td>\n",
       "      <td>1.309617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.247700</td>\n",
       "      <td>1.301351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.216800</td>\n",
       "      <td>1.295668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.131100</td>\n",
       "      <td>1.291234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.147500</td>\n",
       "      <td>1.287957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.232000</td>\n",
       "      <td>1.285691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.226800</td>\n",
       "      <td>1.284238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.203200</td>\n",
       "      <td>1.283301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1392, training_loss=1.2111523399750392, metrics={'train_runtime': 812.1756, 'train_samples_per_second': 13.7, 'train_steps_per_second': 1.714, 'total_flos': 2926612821049344.0, 'train_loss': 1.2111523399750392, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9️⃣ Train\n",
    "# -----------------------------\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voUMoLWC6ErD",
    "outputId": "ecc82005-a406-4039-8b4c-5dcd34907130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA fine-tuning complete! Saved at ./lora_code_model\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 10️ Save Model & Tokenizer\n",
    "# -----------------------------\n",
    "model.save_pretrained(\"./lora_code_model\")\n",
    "tokenizer.save_pretrained(\"./lora_code_model\")\n",
    "print(\"LoRA fine-tuning complete! Saved at ./lora_code_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6veHmbse6-ZI",
    "outputId": "77b255b9-4dc5-4e36-ab8e-3e568fa06453"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Language: python\n",
      "# Function: add_numbers\n",
      "\"\"\"Adds two numbers\"\"\"\n",
      "add_numbers(numbers):\n",
      "        \"\"\"Adds two numbers\"\"\"\n",
      "        numbers = [numbers[0] for n in numbers]\n",
      "        if len(numbers) < 2:\n",
      "            raise ValueError(\"numbers must be integers\")\n",
      "        if len(numbers) > 2:\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "prompt = \"# Language: python\\n# Function: add_numbers\\n\\\"\\\"\\\"Adds two numbers\\\"\\\"\\\"\\nadd_numbers(\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# generation\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,  # give more space for full function\n",
    "    do_sample=True,\n",
    "    temperature=0.3,     # less randomness\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "404337f330764f55b2d58b682b336114",
      "d3b7cb319f7d46908838a3286a77c79b",
      "fcc139b3ad3a48d99a79ff81654ed9c2",
      "636d10c09c1b46d69343d078c2b728f1",
      "c16e103395294b209e5bf2c80dfe4db5",
      "219fd16606ce4d37ae741118ec6fd67f",
      "0bf2f2fdaa1f45ec89d7bcf6a2be05da",
      "dbb012f3831b463390f062d4505fd3cf",
      "e1356203e09c4e04861a049e56be6739",
      "d68d3bdb2e484bd89ea48990c3900315",
      "100f8e9997df4ab48cf3c1e71e916738",
      "ab1689f894254451964c0fb9eee82e1b",
      "0405ec67e752478c98e6660ac8653f95",
      "c519cc11cf634bdbbf87ecce5deff224",
      "669e9d57462649ac92ec8a83c632234f",
      "007737b194a744979dbcc9035e1dc7bb",
      "3b0111728eef49cb82e539b6ba03d95d",
      "7cc0740362314fa4a198375f2e85b7e3",
      "1970fef0f7ec46b383af2f9ed93114b4",
      "68b7f3b51063444e9832f53b42a15f73",
      "3a28067a76264ddf9fcd5b7f5c159204",
      "683a54d5d9834f68a60333d9e01c2177",
      "f86f6e6db8bf4f89ad2b8fe5665a0238",
      "9c70cd8d46ff43a49257b265b7389d82",
      "96bbfe19d60f4ce5a189ced8ab886100",
      "01bb8c2dc1094801a297373980024ee0",
      "54d9b9dc8bfd45d0b653c5fdbb2e882c",
      "916ddcc32d3841548da4fa71bedf4e38",
      "abe7ac2b738a4ff1920f4eb70d2874c8",
      "852047cac4e849809a879bcbaa6a886d",
      "1c82670d26504175ae68d9f1fcdfd7f2",
      "addf7b6412c04a03b8e9c6cad1a4025c",
      "5f6f7cfb13a04b3fb92a99f2cbdf5a1d",
      "e6782077ee264262aa8643d3c9e0cd30",
      "27e3133b021c4e4cb851bcca4f059cd8",
      "d88945c5957843569f4a64225e9e7606",
      "01f6c0321444481ea05a0b03ee625b2d",
      "771e3beb9c9045f4a8f2f9804518791e",
      "5d2bc5d96da34a5e909ca79c191ca7eb",
      "a6b2db663de5487cb800ee3abad79eaa",
      "e701a6050586494fa01569b911438721",
      "df4776a34047477f836b5d51983f0cd7",
      "763c8674d9104056a1f08d98285cdfd8",
      "e7b02198d81e45c1bd3e69b449bd4eaf",
      "52034dfa929d495a9d2ed3652e563778",
      "61e7cfaaa3bb48f793560f18bff5b0ad",
      "d5fbddaa25694d90bf2f8f9a961954ea",
      "ac0f63b96fba443cb78e39184a99a8ab",
      "42ed23b8457641a0a39cd1136f089f9e",
      "21ea6dad9ce94c41bf9dcda63dee5e91",
      "b000dd94dbd14c6488be4ff44f62df62",
      "3cda50c40410409f9fa073902f49c3bd",
      "e6132a45d7c04932ae9e16873b1fd3ed",
      "dd05e0e357424c138afc90fd26a5d3a9",
      "93b1a637269e4b70b7de30ffd59ad9e4",
      "a3c52f68d7da49ad89e5fe059e47e17b",
      "bbf910f8359a41788e9ef19fa7fd8455",
      "491898ddb04f4354b881f7faf694060e",
      "39d6a78f9c40444b8f9a554bc381377b",
      "f02330cf90c5446c89eb3369530baf6d",
      "604ac13a34624c9c9a390da778648317",
      "4ba7d6829383445a8b6b81d30690338a",
      "96034c2a7b3a441b9b9f2a63a4979a54",
      "1683273fdd6c44319ff80c58395eb65e"
     ]
    },
    "id": "kTkbYRYe7t_1",
    "outputId": "e1be0c31-eaa5-466b-806f-22f38798f3fc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404337f330764f55b2d58b682b336114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc0740362314fa4a198375f2e85b7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe7ac2b738a4ff1920f4eb70d2874c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b2db663de5487cb800ee3abad79eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:  24%|##3       |  567kB / 2.37MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b000dd94dbd14c6488be4ff44f62df62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Noobhacker69/Coding-CasualLLM-LORA/commit/856bbe7d23d6682fe5f99cd5bae38c63d434b43c', commit_message='Upload tokenizer', commit_description='', oid='856bbe7d23d6682fe5f99cd5bae38c63d434b43c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Noobhacker69/Coding-CasualLLM-LORA', endpoint='https://huggingface.co', repo_type='model', repo_id='Noobhacker69/Coding-CasualLLM-LORA'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "# Push to Hub (your username/repo_name)\n",
    "repo_name = \"Noobhacker69/Coding-CasualLLM-LORA\"  # you choose the name\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
