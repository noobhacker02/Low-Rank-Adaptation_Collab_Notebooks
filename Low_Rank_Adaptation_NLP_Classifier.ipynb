{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddlScuFbZKrm",
    "outputId": "acad5ff2-4e2c-4029-c0cd-e515f9d72381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes, evaluate\n",
      "Successfully installed bitsandbytes-0.47.0 evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft accelerate bitsandbytes evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVDm8SwbgVmc",
    "outputId": "2e236769-d510-471b-d2b5-6ced303423f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.10.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.35.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, transformers, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.56.1\n",
      "    Uninstalling transformers-4.56.1:\n",
      "      Successfully uninstalled transformers-4.56.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.1.1 pyarrow-21.0.0 transformers-4.56.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade peft transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8OUK0sMTZZpS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vE4o_lAZZdZR"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"  # replace with your base model\n",
    "TASK = \"sst2\"  # sample task from GLUE (binary sentiment)\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-4\n",
    "EPOCHS = 3\n",
    "OUTPUT_DIR = \"./lora_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pVQNPW5wZlbV"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "9ce9ed5f262d4f7a98555f668620447c",
      "bd141bbd4bb44debbfd5007760e1860b",
      "90fada074a9e44bf94b37118135579b8",
      "a562a3925aa14d8590d92a5063feafe6",
      "9455224f7b1346de9259d1cf63800a48",
      "29417cc196ea4e0e9f9cfee6316d33b2",
      "75c41b3324574bb8b4d4982b08414dd7",
      "be9e21eef74a4062879a88767945ec51",
      "247e81e11f644ac88c485e40a18367a5",
      "8299235d258f41cdaf495ac3029a915d",
      "1d0aa75808d046a58651cff8c0d134dd",
      "6acd5597fb354461884e289e688abbba",
      "a1f4763e00cb4f05b0c3dc60f38967dd",
      "76cdf196d75645da8aed02d39020afe6",
      "7e604531325b488ba2aed29cd56c4b51",
      "8b36f56ef32746cabdd51c1b44e0d88f",
      "10e3b5de48254a05966e2b533729732c",
      "69846381346649a995b59e20a1a6eb2f",
      "92b66b2258344cf78b77438aec07baef",
      "44e48cdd0ef742a0a031d4db1df5804b",
      "74c42f58112348628ccaef611a4f002a",
      "ed8a1b90ee1c4a208439ae983524ed17",
      "4f6621e1d75b4d469127097958bb43b6",
      "b9e6cb4004e74497b80832068f5aca92",
      "9a54632455634e61ae58dac5caba3543",
      "3945f945f36f4e159eb197485ea08d43",
      "63295e4b12cf4bbdb1ec54d9825ebe81",
      "83921d8dbfca46119ff2cc8f8e9d260c",
      "a1c28252039e453bb82f8270bd60db8e",
      "e76fde0c3a1b482d8f8fe476ed2d8260",
      "7e59d64a66054eee84258ff0294ab040",
      "67c15422b3c84cdfb8889b2933a2ff96",
      "8b1f673912464aeb9b357e7a091a5156",
      "17db778af4374c779fdda825cdb742be",
      "f535aeb840324010b43ec382ba627b99",
      "ce233463c78141caae4bfa7f4f16213e",
      "3a548dca41a94f12ba4fa25261a68d76",
      "c852070f426648a2b149336b0c15c703",
      "3714887ee91844c4b77d5509c2f41899",
      "36fa1d5aefff4784a64f1faf20481701",
      "9565e48cce32402dbe2e01c9a00abdfc",
      "52839239fef74b0a9622dfca17a5d82b",
      "edb93a016ba24e62a93ef659f93611d3",
      "b14c08ad73464f43a3e4b02595a7d260",
      "ccbfb4210d2c42b1b94b12f02c1281bc",
      "71ac1315ca9f45928d5f9123869f12bb",
      "427577132ce7425c95bd61384bfaea3d",
      "3395d2f4f8ad452fb61e9bff52761753",
      "b2109d883906431da88b03d20a7a7b63",
      "024ba0900cab4419bd5aafb2e7043469",
      "f968c44ef417425783dfdf38374a2636",
      "388c7cadfc9444c787036f47f2be668e",
      "8e754592be6b4bb9bdd401ebca104316",
      "b2a2a8502fe74f92b945651d30a49060",
      "9b5997e8f62344629ae0aa9c717c96b3",
      "9ed51ec1d7224595a10438610a77ae48",
      "cc7b12de1aac4cfb921adbc12b9a5c7b",
      "79c6e488d1ae47fd9bf3cb4d28ae52d9",
      "92c76c59e7944905a5a346bdca49d2ff",
      "68c37c438f074b2086083dc02c80f04b",
      "ba4311775ace46da9b92695f150af71e",
      "b7b300af723c411c97ff9572e7f04af1",
      "e9e77a00134d4d979cc0b4233930a00a",
      "4ee19301c14a4658a7a3e46f2b26c782",
      "9782192dcdf0498aad18a988dcf5d79e",
      "662aa9832c8b424880b7fe811247efe2",
      "b566ef760f1744fc8fc62ae7db79412b",
      "81ac2df97c59499aac6649e8cdd42241",
      "3d2e89b4a3fc41ca911d9d6d25c4b385",
      "7754902f4f584e56825453503be1653a",
      "0fc0cb1262d045ba8aaacab6492b19a3",
      "f9ce1eb6fe1c4059b619d3a32100eaa6",
      "2355712887e5468286308c2dc6ea5a53",
      "8c9e7899e331452e9c9d51d3ea993924",
      "dd5444374b4b420db685d56dc3dfe388",
      "07056d9e523f484aa4eaba1b8851b2f9",
      "3c16b38f60014f2bb30a20e9846d211a",
      "ec865261fff34ca38a7f56b3d3df6b4d",
      "fe4e6fe5c46041eea455687a12be1d72",
      "d7b5c25465f345fe856f73b224f8877c",
      "c22d4e3bc86d44e1a8d578977838fd4e",
      "9639efd52a754aa39aefeda6370ad856",
      "d71bda1d68334d208b946691085bc65f",
      "cff9a744e6994cd09286ab7399453ee0",
      "60baedeeb8934774b866d6af8f13a547",
      "9011f50c0ed6416d957d06b8a40f48c2",
      "a3df7bd5cd4941379be6109a2da98257",
      "df9e73f66e504c08aac69ac0a2f405c8",
      "6e23bf7e9abd4457ae8cbcb89ae068b0",
      "44caf922022f4ed4b695a6b8f595236a",
      "4ca3d89d77ef4a88bbd8dc18f48c14aa",
      "2c46763964a84edfaf7bfd02d7095bbc",
      "c76425989d2c43c3a0792108dbd49c91",
      "2e45b4c5cd1d4d2195ee881507a0a2c9",
      "2a45fb2abb424de1838453275bca8091",
      "dc6670874fdd49c99602ea04d8cbf74d",
      "18e6b91cec244ed088ea543b23033a1f",
      "733a679a1e7d44158430dfc9f5907e04",
      "b0c5b19dce884abd8fb291b9160c2547",
      "71a7f2c7d3364f40a7a82e6008545a85",
      "5bd3b27cf5814967acfc854c6a94ef46",
      "0dbcd97f0ca44fe9aae1825dec268c99",
      "ea945cdb62354d9a98b02d2893b02afb",
      "76462ee344cc40b8bdec3040471421b1",
      "5300a55215c940aabfffc0ce29218e41",
      "6cc131f2add249fca52abbfe8c0e83c8",
      "98ee94c2ccb1403583dab870fd47cb68",
      "a00bf38008a74e53b6cea1570659d364",
      "12cffc791b7546a1b20fdb4ab60702c5",
      "0388f49f8ada443f9deafa333f520288",
      "c943147342904a8f8845fdccd1b2993e",
      "dbfe98850125486a903c33c52fb88a48",
      "0f1e9160f8014a64a718fcc4a073a188",
      "662162fefa1547878df67ab6152d4c7b",
      "d323d111c6014fff864188459014c011",
      "768197f57fca4b5caf108499d9f7b9ab",
      "eceea6fe3f154956909e1aa35474e418",
      "04e5ea06bd314eefbe454b75d19bf930",
      "4be68943748445c8bab78178745f4c70",
      "eadf49ec6a2a4f9796cc6d3e4f251de5",
      "c02c84d09f924e558d3bedb5d4cbeaf2"
     ]
    },
    "id": "qb2ri6b5Znly",
    "outputId": "2f9447c5-d3d0-43ae-8cb6-6c210e059a35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce9ed5f262d4f7a98555f668620447c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acd5597fb354461884e289e688abbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sst2/train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6621e1d75b4d469127097958bb43b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sst2/validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17db778af4374c779fdda825cdb742be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sst2/test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbfb4210d2c42b1b94b12f02c1281bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed51ec1d7224595a10438610a77ae48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b566ef760f1744fc8fc62ae7db79412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec865261fff34ca38a7f56b3d3df6b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e23bf7e9abd4457ae8cbcb89ae068b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a7f2c7d3364f40a7a82e6008545a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c943147342904a8f8845fdccd1b2993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", TASK)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "d0f293beb8834d35a813a50265800c20",
      "94951170dc1c4d3b88b8ae03adb1d7b6",
      "cd4d49a92dbf4eeaaaea185237d27a15",
      "a9cf5de01ac540db872aa59103afe338",
      "1d90c0282ff942f8947a8b4f2fee1c21",
      "3e007fe2fcd44e8faa711131a0b687db",
      "4f35831affe74f2f8e579d7b82e40fe0",
      "15df36447bdd44519e26f1cb423756a4",
      "0c4dbdcd33d64e7faeee707d5918790a",
      "e1648da3887b4a24ad0e29426e314ccb",
      "4eaa878ac3494f3aa7819f060c5d7e82",
      "ba20bc0ebde047da854e342bf04430bb",
      "7f4e98ed2d6643c9ab6231a2f1e5f093",
      "723cb76e18404942bd0667b9b10269e2",
      "47ea1affae1c4c3c82a652413b8dca63",
      "0c6834f350034faeb508a64fe3eeb71f",
      "aacadb9a96da4ba48c1b1aa8fd45e073",
      "35ebe982d60f455c958b19d316f7b6b1",
      "b7bef498cad9487f853919e53c115a5d",
      "9c1d23faf3f9442d80ee662e8ba0a267",
      "c594f4045d5d42bf81b20af467eb2c43",
      "bad699ca5e5440118df50816e972d22f",
      "882dada707694978ac6ac9b55d226ef9",
      "bf5c65bd7ebe409cba4df486c4a1ba88",
      "dbc5c57dbffe40f99c0eb587a6380025",
      "94580e9c54184d72a8e55119f9010e08",
      "0bdf3470b771478a9827af08888f0412",
      "49da3e9364cd4552b07518cac29736fc",
      "8fb2e3cb47b44aa492c300cfd30de669",
      "acc51bebf20a4ef3b550b8eb17ee0fcb",
      "e35740058a834253b7cac99eb2db333b",
      "a02fe954e12842be8e058a123f7b7015",
      "3ec8e21b778d40f2bdb746f18499f3cd"
     ]
    },
    "id": "JLILRE_PZowq",
    "outputId": "197ab152-4dcd-4820-da85-b49cefd9d481"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f293beb8834d35a813a50265800c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba20bc0ebde047da854e342bf04430bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882dada707694978ac6ac9b55d226ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"sentence\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694,
     "referenced_widgets": [
      "9a6f3a5957404ae4af6bbc840bbb8f15",
      "32a1364a06ea43d3ba9889e5319b31e6",
      "e26b17df0da748c288a6cd1256c35aa2",
      "17ab02a79b1b489282bbf23b56bfe83c",
      "f1a6567f479a416fa0191fe46757205f",
      "23d4e7156759444598ea20af211d55b7",
      "2cc98f7ff67d420f98f4f6694acd3822",
      "946a4ebbe4544194b484c7dbd1de96b2",
      "97aa7e1e932449358618e1b7b782952a",
      "33b72b9a96f643a6bf9d2e223d1573aa",
      "dd87ffa0a1af4bf1a3c8a19bde2b92a0"
     ]
    },
    "id": "aisgcuzsZqNi",
    "outputId": "fdb8d2c0-9190-4d93-d410-5ecfbe472c1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6f3a5957404ae4af6bbc840bbb8f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load base model ---\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihZoBkZvb79B",
    "outputId": "d78ea3e2-a82b-4fe9-b249-4470ae7e59da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "distilbert\n",
      "distilbert.embeddings\n",
      "distilbert.embeddings.word_embeddings\n",
      "distilbert.embeddings.position_embeddings\n",
      "distilbert.embeddings.LayerNorm\n",
      "distilbert.embeddings.dropout\n",
      "distilbert.transformer\n",
      "distilbert.transformer.layer\n",
      "distilbert.transformer.layer.0\n",
      "distilbert.transformer.layer.0.attention\n",
      "distilbert.transformer.layer.0.attention.dropout\n",
      "distilbert.transformer.layer.0.attention.q_lin\n",
      "distilbert.transformer.layer.0.attention.k_lin\n",
      "distilbert.transformer.layer.0.attention.v_lin\n",
      "distilbert.transformer.layer.0.attention.out_lin\n",
      "distilbert.transformer.layer.0.sa_layer_norm\n",
      "distilbert.transformer.layer.0.ffn\n",
      "distilbert.transformer.layer.0.ffn.dropout\n",
      "distilbert.transformer.layer.0.ffn.lin1\n",
      "distilbert.transformer.layer.0.ffn.lin2\n",
      "distilbert.transformer.layer.0.ffn.activation\n",
      "distilbert.transformer.layer.0.output_layer_norm\n",
      "distilbert.transformer.layer.1\n",
      "distilbert.transformer.layer.1.attention\n",
      "distilbert.transformer.layer.1.attention.dropout\n",
      "distilbert.transformer.layer.1.attention.q_lin\n",
      "distilbert.transformer.layer.1.attention.k_lin\n",
      "distilbert.transformer.layer.1.attention.v_lin\n",
      "distilbert.transformer.layer.1.attention.out_lin\n",
      "distilbert.transformer.layer.1.sa_layer_norm\n",
      "distilbert.transformer.layer.1.ffn\n",
      "distilbert.transformer.layer.1.ffn.dropout\n",
      "distilbert.transformer.layer.1.ffn.lin1\n",
      "distilbert.transformer.layer.1.ffn.lin2\n",
      "distilbert.transformer.layer.1.ffn.activation\n",
      "distilbert.transformer.layer.1.output_layer_norm\n",
      "distilbert.transformer.layer.2\n",
      "distilbert.transformer.layer.2.attention\n",
      "distilbert.transformer.layer.2.attention.dropout\n",
      "distilbert.transformer.layer.2.attention.q_lin\n",
      "distilbert.transformer.layer.2.attention.k_lin\n",
      "distilbert.transformer.layer.2.attention.v_lin\n",
      "distilbert.transformer.layer.2.attention.out_lin\n",
      "distilbert.transformer.layer.2.sa_layer_norm\n",
      "distilbert.transformer.layer.2.ffn\n",
      "distilbert.transformer.layer.2.ffn.dropout\n",
      "distilbert.transformer.layer.2.ffn.lin1\n",
      "distilbert.transformer.layer.2.ffn.lin2\n",
      "distilbert.transformer.layer.2.ffn.activation\n",
      "distilbert.transformer.layer.2.output_layer_norm\n",
      "distilbert.transformer.layer.3\n",
      "distilbert.transformer.layer.3.attention\n",
      "distilbert.transformer.layer.3.attention.dropout\n",
      "distilbert.transformer.layer.3.attention.q_lin\n",
      "distilbert.transformer.layer.3.attention.k_lin\n",
      "distilbert.transformer.layer.3.attention.v_lin\n",
      "distilbert.transformer.layer.3.attention.out_lin\n",
      "distilbert.transformer.layer.3.sa_layer_norm\n",
      "distilbert.transformer.layer.3.ffn\n",
      "distilbert.transformer.layer.3.ffn.dropout\n",
      "distilbert.transformer.layer.3.ffn.lin1\n",
      "distilbert.transformer.layer.3.ffn.lin2\n",
      "distilbert.transformer.layer.3.ffn.activation\n",
      "distilbert.transformer.layer.3.output_layer_norm\n",
      "distilbert.transformer.layer.4\n",
      "distilbert.transformer.layer.4.attention\n",
      "distilbert.transformer.layer.4.attention.dropout\n",
      "distilbert.transformer.layer.4.attention.q_lin\n",
      "distilbert.transformer.layer.4.attention.k_lin\n",
      "distilbert.transformer.layer.4.attention.v_lin\n",
      "distilbert.transformer.layer.4.attention.out_lin\n",
      "distilbert.transformer.layer.4.sa_layer_norm\n",
      "distilbert.transformer.layer.4.ffn\n",
      "distilbert.transformer.layer.4.ffn.dropout\n",
      "distilbert.transformer.layer.4.ffn.lin1\n",
      "distilbert.transformer.layer.4.ffn.lin2\n",
      "distilbert.transformer.layer.4.ffn.activation\n",
      "distilbert.transformer.layer.4.output_layer_norm\n",
      "distilbert.transformer.layer.5\n",
      "distilbert.transformer.layer.5.attention\n",
      "distilbert.transformer.layer.5.attention.dropout\n",
      "distilbert.transformer.layer.5.attention.q_lin\n",
      "distilbert.transformer.layer.5.attention.k_lin\n",
      "distilbert.transformer.layer.5.attention.v_lin\n",
      "distilbert.transformer.layer.5.attention.out_lin\n",
      "distilbert.transformer.layer.5.sa_layer_norm\n",
      "distilbert.transformer.layer.5.ffn\n",
      "distilbert.transformer.layer.5.ffn.dropout\n",
      "distilbert.transformer.layer.5.ffn.lin1\n",
      "distilbert.transformer.layer.5.ffn.lin2\n",
      "distilbert.transformer.layer.5.ffn.activation\n",
      "distilbert.transformer.layer.5.output_layer_norm\n",
      "pre_classifier\n",
      "classifier\n",
      "dropout\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UD_NSB1CZrb7"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_lin\",\"v_lin\"],  # correct for DistilBERT\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SE4fZppbZtFb",
    "outputId": "7a6cee6e-d1f6-4d82-f7b5-a093d686fab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 67,842,052 || trainable%: 1.3075\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # shows only LoRA params are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "20ba18c37502490ebd145d3be04c451e",
      "cc4e46c33c4745be82ba7a881de2491e",
      "dca927f6120545c5bff217ef9e7ae189",
      "5a93dce0caf14121912a06bdadd5bd49",
      "0ea94eef874c4d4d9144c4510f325e04",
      "ad0ae31a47ae43428a220f30642a665a",
      "ba616040320d4c008d26149edfae9d2d",
      "dc913383d9b946368563e09049c19354",
      "52e897edc960429a8f29b86dfb5636d5",
      "b982bfab578c4d8da87a5dae7068f4d0",
      "d2429fb68d814babb3d24943145230e6"
     ]
    },
    "id": "I-ZpIm6Sdxxb",
    "outputId": "e72ffd12-2c5f-4df5-fe21-7639302f5303"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ba18c37502490ebd145d3be04c451e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Training ---\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "34ZawDX2ei4x"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True if device==\"cuda\" else False,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LXvD72JXelt3",
    "outputId": "ab95ad6f-042a-4b1a-b6db-23a52f8e497c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12630' max='12630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12630/12630 09:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.269761</td>\n",
       "      <td>0.894495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.314147</td>\n",
       "      <td>0.897936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.345756</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12630, training_loss=0.21770143307869338, metrics={'train_runtime': 580.7249, 'train_samples_per_second': 347.922, 'train_steps_per_second': 21.749, 'total_flos': 6828804290442240.0, 'train_loss': 0.21770143307869338, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200,
     "referenced_widgets": [
      "f433fc6e9562423ca80c75d30fb3dc1c",
      "8e7e02dc27bd401aaf467734af5fc711",
      "99d32c1f30fb4e0cb2610938fc6bf096",
      "e155f37f41134567b827c4881b39abea",
      "d10d37a8bda44f5cb0bd1e74f4cf4d4f",
      "8bb3e16d3ac54423959369de749f5cab",
      "85ed2ca3650142a2a89a6818579f0a91",
      "93bc24a3f7fd416582cea304a636f0a5",
      "f53b22c6db67454a9ba367429c67c7a6",
      "a85d942e93384f83acc4ca481a351004",
      "db8a736f75b0457d9c94fee6107bebf8",
      "56ec2998beee4f00b3f4b73b2f529b7a",
      "d80aef7a95aa4416bf8199ea42109223",
      "e0a5d9fa372f468b968006e8e785317d",
      "6001c083f50a4b279c7d2018b5533d19",
      "9d93b6b4228d4214bd7f6303a2fd85ba",
      "a8b62850ccc646e5b6a0bd777a3ed579",
      "aa43ac710fb94cfcaa175f733a04bd19",
      "19297cace4aa4508a5a1f2ba12c3f0b5",
      "c820d47cedf24c06849bcfdc6967cf1b",
      "2d48a5b2ef4c4d8abe7bce8620d2a9e3",
      "f679c99b9fc04663946f9cc6272e1fb2",
      "f6ec38795f054c418f38a0684579857d",
      "2900b6911083426f9fc7091f7aafed5f",
      "4cd1e2c49d454280929b09333616c802",
      "50f452af62884c81902cc6e1b33d35b3",
      "b9180b0575ee44c8aad852eb825aa260",
      "5e1d5fe54b1344f6bd9ef7d6dc3bda1e",
      "b300de61dcd1481d9bd8a812ff589814",
      "8e055d12e38e40e99bb9510699f06e27",
      "8e6d36f6397c44e796d46494892592b6",
      "4e85724ba07b410a86e59a810e8275b9",
      "8b3bbf5e35c54adba3b997a97005ff13",
      "a6c36d8cdc714f2ca6ea2cbe29c1b89f",
      "395c9730bf2a423b88cff7eadb0551ef",
      "57bf1ec27926448eb7ec4e753e333ba8",
      "c857327abf28416b926c8a3593a61f37",
      "da20d5f4fe134ed38a581445deb879d1",
      "d6a3012bc23b49aba42eff9588f4a117",
      "bc1d21b6d9c540a8a5668bccf6ea4134",
      "5a74e224a56c4b29965116220204917b",
      "0c2332390fdd4ef0998423279612ec36",
      "4e44e68a3601477f99cb9cff0577c7e4",
      "3e13671bdaad4929a170abef421aa646"
     ]
    },
    "id": "pG51Bkk8oB4I",
    "outputId": "8ad74750-7510-4110-e452-db38e3e83b0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f433fc6e9562423ca80c75d30fb3dc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ec2998beee4f00b3f4b73b2f529b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ec38795f054c418f38a0684579857d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c36d8cdc714f2ca6ea2cbe29c1b89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Define label mapping\n",
    "label2id = {\"negative\": 0, \"positive\": 1}  # or spam example {\"not spam\":0, \"spam\":1}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Load your LoRA-adapted model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Noobhacker69/Low-Rank_Adaptation_NLP_Classifier\")\n",
    "\n",
    "# Set the labels in the model config\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Noobhacker69/Low-Rank_Adaptation_NLP_Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PRx9W1Tento",
    "outputId": "5fe11648-5798-45c4-d77c-f9a113addc93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA fine-tuning complete! Saved at: ./lora_model\n"
     ]
    }
   ],
   "source": [
    "model.config.id2label = {0: \"negative\", 1: \"positive\"}\n",
    "model.config.label2id = {\"negative\": 0, \"positive\": 1}\n",
    "\n",
    "# Save LoRA-adapted model\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"LoRA fine-tuning complete! Saved at:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "5c60d0bcba0c4821a82f6d959c65c633",
      "7620e352e531479383d2747c31281d17",
      "6c2a1778e2f74d31a99520d0b7509ea3",
      "919da98a37414c7c9d2244309f9c0125",
      "5a0589124ed24f57b7615c52c5bfa5a1",
      "6d689a9baef147f9af2754ddd44623dc",
      "b19c80b7c51346edadb89e5e9907fd1a",
      "c3028f9a5f2c40e3951085f2a30162bc",
      "65b53a4de98440f1b5021eab5127b499",
      "1f215a8d044c489eadb84e080babf97f",
      "0400bd1d8ec04a669879c3d18a9290b0",
      "5a9f4a4183ca45a0823f239a3df8d8c2",
      "d6c97a7174384fa29fc2d92ad155a059",
      "4a8cf03aed2b4ece9107e5009721a8a9",
      "dec33ca3a0c944d68153bf660b59951c",
      "72b28d12ddf94427ba5d4e6d2a28926d",
      "3e6b529babe14bdd807f6f0ea318ded6",
      "7b3c57a1ede546c1a0290d675a8910f2",
      "7b3a076a23ef49139c1a9a1b837a2b4d",
      "3cfab8887b7a41d5b62b4f1c77776ca5",
      "3c96cf301f444274842383913b0bbb97",
      "129ba827186d46f090ab31307fc97ad4",
      "bf8e6a65ab814f41b4cb1e26c39e1c91",
      "796029ba2c9e49cf830922193ea0069a",
      "5c8c0fae0d604cb185ec0febd4bf2bb6",
      "352bc7f780ac40ebb9bec4042442e461",
      "d61d55acdcd44365ab7f932fd7649509",
      "601f61327a9e4a3993e5071ea327a301",
      "6bac023206ad40ecbe380f267a79edb8",
      "b3dc4864694a4632acd2ad8c6f4a3c1d",
      "f2c656d170874a25b20ee27589081220",
      "b4454be2b0674fb287324fe35fc5aa93",
      "bff827e7418b4159bdde461ae50a1adc"
     ]
    },
    "id": "7iHpW7floOuB",
    "outputId": "862a95fa-d344-484d-fa16-20f4aa93d9e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c60d0bcba0c4821a82f6d959c65c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9f4a4183ca45a0823f239a3df8d8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8e6a65ab814f41b4cb1e26c39e1c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors: 100%|##########| 3.55MB / 3.55MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Noobhacker69/Low-Rank_Adaptation_NLP_Classifier/commit/ae6f28d5a78d961f456ac7bfd3fb4a9ecb7498ca', commit_message='Upload tokenizer', commit_description='', oid='ae6f28d5a78d961f456ac7bfd3fb4a9ecb7498ca', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Noobhacker69/Low-Rank_Adaptation_NLP_Classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='Noobhacker69/Low-Rank_Adaptation_NLP_Classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"Noobhacker69/Low-Rank_Adaptation_NLP_Classifier\")\n",
    "tokenizer.push_to_hub(\"Noobhacker69/Low-Rank_Adaptation_NLP_Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "341479386fbe40eab63c6dc6bd7b01ee",
      "f4f84b15e98a40d48a1bad5bf11d7e2c",
      "a4caa6caefeb415492aed91c78fdabbd",
      "c94232012d0b43f183add422b3e1f196",
      "603824dfa377422484c07b2421198725",
      "f4db23d849ad4dcab43b72bfbcb3ece3",
      "e255c39340974a1dbec6ad989221f11d",
      "5963ecc079804793880a44d0b3165d8e",
      "0c39e7c7f0824ab88554e679737ddfb8",
      "c97a4fff04bb4a45a5e991f7d8dd6814",
      "7771c9424e3941028e16c3520979fe28",
      "85cd442f6686419cadca601009aea538",
      "f9dd692a3ca941ff8c22bdd3e201409f",
      "91d5586397a541c1978e848be4a61dca",
      "edc23b377f514ad3b1cb72bab8165afb",
      "370ab276b50041b7b1b7131ee495e60e",
      "8dbcece0dceb4790815689282a3ab38a",
      "ee091f58108440d6adfa7e950ec1cf61",
      "1d5d3968ca394501a6e122b84781b55a",
      "8765b00db59946669ab244e23605232d"
     ]
    },
    "id": "0sXChZdqhmci",
    "outputId": "0cc92742-bbab-4bdd-bd93-483deb6b7380"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341479386fbe40eab63c6dc6bd7b01ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "5193a42ce1544b0c8b4767497915570d",
      "1ce45371ff094f28898dcecc3cac165c",
      "4152090d373141feb03e9551cb4cde08",
      "37bb2b05e3434fa3b30408fc11312912",
      "7cd332b5c5a24f2f90cf32cecef5606d",
      "860a382fae34496b9f09ed075553552d",
      "2357f2f81ea64e2787e804e0daee30cc",
      "ae421b8b586f4487881d725f6a206206",
      "25370fc25a9e499fb2d71fec438b21b7",
      "1ba1122cd806440da44b059dbbb62511",
      "f4e8ab6b7154445c8ee6fcf6d8111144",
      "21d08f6d06f545219d1c698f39ea1fd2",
      "fe8a1527103d4b92904c108b284b7a66",
      "f2d052280876472da093af07806f4ed2",
      "0e1ac26090f64b7dbe2d73e7e23737b6",
      "7892cdcf4e7946c1b3fcc3512560e545",
      "e7b3b4d33de84b1db2509c3fcb0a2c80",
      "012a5de508b748c0b1e814adcb8a075b",
      "eda101e5b4e64d19ae78cca0d2991827",
      "83830b7160b14fce83b1e88a14178e00",
      "0713f15386dc44f483d7eb6f0c884ee8",
      "d74d11dc567d47b392afbd579fe643c0",
      "1a2923d74ddd4844b15869cef7dbc0a6",
      "f93551fe40434067980beac8ac2de6cc",
      "7f37ac724c924bdeb6ad9cedc867da3e",
      "48db756e8c854a78a6e067382d1c6a46",
      "dca4e7e29cd14c9386c8d6f946271944",
      "175aefa824d843a0bcbeed4ed140af63",
      "add7f45d1be54213ad67067f9f310310",
      "764c6cef57db4b759ec081240e62e7b6",
      "87d65d2513e248e491d45fa4834df46c",
      "ca03fc7f2e9c4adda9b52c610fbbb7d6",
      "e69fd376818947cfaea8dd5c2bf90de3"
     ]
    },
    "id": "5m41pvaPhonh",
    "outputId": "1d9af602-d79a-4134-fceb-c6f3f5172991"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5193a42ce1544b0c8b4767497915570d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d08f6d06f545219d1c698f39ea1fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2923d74ddd4844b15869cef7dbc0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors: 100%|##########| 3.55MB / 3.55MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Noobhacker69/Low-Rank_Adaptation_NLP_Classifier/commit/ae6f28d5a78d961f456ac7bfd3fb4a9ecb7498ca', commit_message='Upload tokenizer', commit_description='', oid='ae6f28d5a78d961f456ac7bfd3fb4a9ecb7498ca', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Noobhacker69/Low-Rank_Adaptation_NLP_Classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='Noobhacker69/Low-Rank_Adaptation_NLP_Classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push to Hub (your username/repo_name)\n",
    "repo_name = \"Noobhacker69/Low-Rank_Adaptation_NLP_Classifier\"  # you choose the name\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dIOZWRGiJG2",
    "outputId": "a81cb118-9531-41a2-b52d-d994eba63fd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"Noobhacker69/Low-Rank_Adaptation_NLP_Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgWD9s28icaP",
    "outputId": "50d6a416-ab3b-4923-e6d8-ec2b81b04e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9992761015892029}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier(\"I love Hugging Face!\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
